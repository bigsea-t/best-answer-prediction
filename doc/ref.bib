@article{Agarwal2012,
author = {Agarwal, Arvind and Gondek, David C and Lawrence, Richard D},
doi = {10.1145/2396761.2396867},
file = {:Users/bigsea/Dropbox/Mendely/Agarwal, Gondek, Lawrence - 2012 - Learning to Rank for Robust Question Answering Categories and Subject Descriptors.pdf:pdf},
isbn = {9781450311564},
journal = {Cikm},
keywords = {j,ny,question-answering,rank-aggregation,ranking,t,the internship at ibm,the part of this,watson research center,work was done during,yorktown heights},
mendeley-groups = {cQA},
number = {2},
pages = {833--842},
title = {{Learning to Rank for Robust Question Answering Categories and Subject Descriptors}},
year = {2012}
}
@article{Agichtein2008,
abstract = {Community Question Answering has emerged as a popu- lar and effective paradigm for a wide range of information needs. For example, to find out an obscure piece of trivia, it is now possible and even very effective to post a question on a popular community QA site such as Yahoo! Answers, and to rely on other users to provide answers, often within min- utes. The importance of such community QA sites is magni- fied as they create archives of millions of questions and hun- dreds of millions of answers, many of which are invaluable for the information needs of other searchers. However, to make this immense body of knowledge accessible, effective answer retrieval is required. In particular, as any user can con- tribute an answer to a question, the majority of the content reflects personal, often unsubstantiated opinions. A rank- ing that combines both relevance and quality is required to make such archives usable for factual information retrieval. This task is challenging, as the structure and the contents of community QA archives differ significantly from the web setting. To address this problem we present a general rank- ing framework for factual information retrieval from social media. Results of a large scale evaluation demonstrate that our method is highly effective at retrieving well-formed, fac- tual answers to questions, as evaluated on a standard factoid QA benchmark. We also show that our learning framework can be tuned with the minimum of manual labeling. Finally, we provide result analysis to gain deeper understanding of which features are significant for social media search and re- trieval. Our system can be used as a crucial building block for combining results from a variety of social media content with general web search results, and to better integrate so- cial media content for effective information access.},
author = {Agichtein, Eugene},
doi = {10.1145/1367497.1367561},
file = {:Users/bigsea/Dropbox/Mendely/Agichtein - 2008 - Finding the Right Facts in the Crowd Factoid Question Answering over Social Media Categories and Subject Descriptors.pdf:pdf},
isbn = {9781605580852},
journal = {Www},
keywords = {community,question answering,ranking},
mendeley-groups = {cQA},
pages = {467--476},
title = {{Finding the Right Facts in the Crowd : Factoid Question Answering over Social Media Categories and Subject Descriptors}},
year = {2008}
}
@article{Dalip2013,
abstract = {Collaborative web sites, such as collaborative encyclopedias, blogs, and forums, are characterized by a loose edit control, which allows anyone to freely edit their content. As a consequence, the quality of this content raises much concern. To deal with this, many sites adopt manual quality control mechanisms. However, given their size and change rate, manual assessment strategies do not scale and content that is new or unpopular is seldom reviewed. This has a negative impact on the many services provided, such as ranking and recommendation. To tackle with this problem, we propose a learn- ing to rank (L2R) approach for ranking answers in Q{\&}A forums. In particular, we adopt an approach based on Random Forests and represent query and answer pairs using eight different groups of features. Some of these features are used in the Q{\&}A domain for the first time. Our L2R method was trained to learn the answer rat- ing, based on the feedback users give to answers in Q{\&}A forums. Using the proposed method, we were able (i) to outperform a state of the art baseline with gains of up to 21{\%} in NDCG, a metric used to evaluate rankings; we also conducted a comprehensive study of the features, showing that (ii) review and user features are the most important in the Q{\&}A domain although text features are useful for assessing quality of new answers; and (iii) the best set of new fea- tures we proposed was able to yield the best quality rankings.},
author = {Dalip, Daniel Hasan and Gon{\c{c}}alves, Marcos Andr{\'{e}} and Cristo, Marco and Calado, Pavel},
doi = {10.1145/2484028.2484072},
file = {:Users/bigsea/Dropbox/Mendely/Dalip et al. - 2013 - Exploiting user feedback to learn to rank answers in q{\&}a forums a case study with stack overflow.pdf:pdf},
isbn = {9781450320344},
journal = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval - SIGIR '13},
keywords = {answer quality,content quality assessment,learning to rank,q{\&}a forums},
mendeley-groups = {cQA},
pages = {543},
title = {{Exploiting user feedback to learn to rank answers in q{\&}a forums: a case study with stack overflow}},
url = {http://dl.acm.org/citation.cfm?id=2484028.2484072},
year = {2013}
}
@article{Feng2015,
abstract = {We apply a general deep learning framework to address the non-factoid question answering task. Our approach does not rely on any linguistic tools and can be applied to different lan-guages or domains. Various architectures are presented and compared. We create and release a QA corpus and setup a new QA task in the insurance domain. Experimental results demonstrate superior performance compared to the baseline methods and various technologies give further improvements. For this highly challenging task, the top-1 accuracy can reach up to 65.3{\%} on a test set, which indicates a great potential for practical use.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.01585v2},
author = {Feng, Minwei and Xiang, Bing and Glass, Michael R and Wang, Lidan and Zhou, Bowen},
eprint = {arXiv:1508.01585v2},
file = {:Users/bigsea/Dropbox/Mendely/Feng et al. - 2015 - APPLYING DEEP LEARNING TO ANSWER SELECTION A STUDY AND AN OPEN TASK.pdf:pdf},
keywords = {()},
mendeley-groups = {cQA},
title = {{APPLYING DEEP LEARNING TO ANSWER SELECTION: A STUDY AND AN OPEN TASK}},
year = {2015}
}
@article{Filice2015,
author = {Filice, Simone and Da, Giovanni and Martino, San and Barr, Alberto and Nakov, Preslav and Moschitti, Alessandro},
file = {:Users/bigsea/Dropbox/Mendely/Filice et al. - 2015 - Thread-Level Information for Comment Classification in Community Question Answering.pdf:pdf},
journal = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
mendeley-groups = {cQA},
pages = {687--693},
title = {{Thread-Level Information for Comment Classification in Community Question Answering}},
year = {2015}
}
@article{He2015,
abstract = {Modeling sentence similarity is compli-cated by the ambiguity and variability of linguistic expression. To cope with these challenges, we propose a model for com-paring sentences that uses a multiplicity of perspectives. We first model each sentence using a convolutional neural network that extracts features at multiple levels of gran-ularity and uses multiple types of pooling. We then compare our sentence representa-tions at several granularities using multi-ple similarity metrics. We apply our model to three tasks, including the Microsoft Re-search paraphrase identification task and two SemEval semantic textual similarity tasks. We obtain strong performance on all tasks, rivaling or exceeding the state of the art without using external resources such as WordNet or parsers.},
author = {He, Hua and Gimpel, Kevin and Lin, Jimmy},
file = {:Users/bigsea/Dropbox/Mendely/He, Gimpel, Lin - 2015 - Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks.pdf:pdf},
mendeley-groups = {cQA},
pages = {1576--1586},
publisher = {Association for Computational Linguistics},
title = {{Multi-Perspective Sentence Similarity Modeling with Convolutional Neural Networks}},
year = {2015}
}
@article{Hoogeveen2015,
author = {Hoogeveen, Doris and Verspoor, Karin M and Baldwin, Timothy},
file = {:Users/bigsea/Dropbox/Mendely/Hoogeveen, Verspoor, Baldwin - 2015 - CQADupStack A Benchmark Data Set for Community Question-Answering Research.pdf:pdf},
isbn = {9781450340403},
mendeley-groups = {cQA},
pages = {1--3},
title = {{CQADupStack : A Benchmark Data Set for Community Question-Answering Research}},
year = {2015}
}
@article{Hu,
abstract = {Semantic matching is of central importance to many natural language tasks [2, 28]. A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them. As a step toward this goal, we propose convolutional neural network models for matching two sentences, by adapting the convolutional strategy in vision and speech. The proposed models not only nicely represent the hierarchical structures of sentences with their layer-by-layer composition and pooling, but also capture the rich matching patterns at different levels. Our models are rather generic, requiring no prior knowledge on language, and can hence be applied to matching tasks of different nature and in different languages. The empirical study on a variety of matching tasks demon-strates the efficacy of the proposed model on a variety of matching tasks and its superiority to competitor models.},
author = {Hu, Baotian and Lu, Zhengdong and Li, Hang and Chen, Qingcai},
file = {:Users/bigsea/Dropbox/Mendely/Hu et al. - Unknown - Convolutional Neural Network Architectures for Matching Natural Language Sentences.pdf:pdf},
mendeley-groups = {cQA},
title = {{Convolutional Neural Network Architectures for Matching Natural Language Sentences}}
}
@article{Iyyer2014,
author = {Iyyer, M and Boyd-Graber, J},
file = {:Users/bigsea/Dropbox/Mendely/Iyyer, Boyd-Graber - 2014 - A neural network for factoid question answering over paragraphs.pdf:pdf},
journal = {Proceedings of the  {\ldots}},
mendeley-groups = {cQA},
pages = {633--644},
title = {{A neural network for factoid question answering over paragraphs}},
url = {http://www.cs.colorado.edu/{~}jbg/docs/2014{\_}emnlp{\_}qb{\_}rnn.pdf},
year = {2014}
}
@article{Lu,
abstract = {Many machine learning problems can be interpreted as learning for matching two types of objects (e.g., images and captions, users and products, queries and doc-uments, etc.). The matching level of two objects is usually measured as the inner product in a certain feature space, while the modeling effort focuses on mapping of objects from the original space to the feature space. This schema, although proven successful on a range of matching tasks, is insufficient for capturing the rich struc-ture in the matching process of more complicated objects. In this paper, we pro-pose a new deep architecture to more effectively model the complicated matching relations between two objects from heterogeneous domains. More specifically, we apply this model to matching tasks in natural language, e.g., finding sensible re-sponses for a tweet, or relevant answers to a given question. This new architecture naturally combines the localness and hierarchy intrinsic to the natural language problems, and therefore greatly improves upon the state-of-the-art models.},
author = {Lu, Zhengdong and Li, Hang},
file = {:Users/bigsea/Dropbox/Mendely/Lu, Li - Unknown - A Deep Architecture for Matching Short Texts.pdf:pdf},
mendeley-groups = {cQA},
title = {{A Deep Architecture for Matching Short Texts}}
}
@article{Moschitti2007,
abstract = {We study the impact of syntactic and shallow semantic information in automatic classifi- cation of questions and answers and answer re-ranking. We define (a) new tree struc- tures based on shallow semantics encoded in Predicate Argument Structures (PASs) and (b) new kernel functions to exploit the representational power of such structures with Support Vector Machines. Our ex- periments suggest that syntactic information helps tasks such as question/answer classifi- cation and that shallow semantics gives re- markable contribution when a reliable set of PASs can be extracted, e.g. from answers.},
author = {Moschitti, Alessandro and Quarteroni, Silvia and Basili, Roberto and Manandhar, Suresh},
file = {:Users/bigsea/Dropbox/Mendely/Moschitti et al. - 2007 - Exploiting Syntactic and Shallow Semantic Kernels for Question Answer Classification.pdf:pdf},
isbn = {9781932432862},
journal = {Acl},
mendeley-groups = {cQA},
number = {June},
pages = {776--783},
title = {{Exploiting Syntactic and Shallow Semantic Kernels for Question Answer Classification}},
url = {http://eprints.whiterose.ac.uk/7352/},
year = {2007}
}
@article{Nogueira,
abstract = {Relation classification is an important se-mantic processing task for which state-of-the-art systems still rely on costly hand-crafted features. In this work we tackle the relation classification task using a convo-lutional neural network that performs clas-sification by ranking (CR-CNN). We pro-pose a new pairwise ranking loss function that makes it easy to reduce the impact of artificial classes. We perform experi-ments using the the SemEval-2010 Task 8 dataset, which is designed for the task of classifying the relationship between two nominals marked in a sentence. Using CR-CNN, we outperform the state-of-the-art for this dataset and achieve a F1 of 84.1 without using any costly handcrafted fea-tures. Additionally, our experimental re-sults show that: (1) our approach is more effective than CNN followed by a soft-max classifier; (2) omitting the representa-tion of the artificial class Other improves both precision and recall; and (3) using only word embeddings as input features is enough to achieve state-of-the-art results if we consider only the text between the two target nominals.},
author = {Nogueira, C{\'{\i}}cero and Santos, Dos and Xiang, Bing and Zhou, Bowen},
file = {:Users/bigsea/Dropbox/Mendely/Nogueira et al. - Unknown - Classifying Relations by Ranking with Convolutional Neural Networks.pdf:pdf},
mendeley-groups = {cQA},
pages = {626--634},
title = {{Classifying Relations by Ranking with Convolutional Neural Networks}}
}
@article{Pappas2014,
author = {Pappas, Nikolaos and Popescu-Belis, Andrei},
file = {:Users/bigsea/Dropbox/Mendely/Pappas, Popescu-Belis - 2014 - Explaining the Stars Weighted Multiple-Instance Learning for Aspect-Based Sentiment Analysis.pdf:pdf},
journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
mendeley-groups = {cQA},
pages = {455--466},
title = {{Explaining the Stars: Weighted Multiple-Instance Learning for Aspect-Based Sentiment Analysis}},
url = {http://aclweb.org/anthology/D14-1052},
year = {2014}
}
@article{Pennington2014,
abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arith- metic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global log- bilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word co- occurrence matrix, rather than on the en- tire sparse matrix or on individual context windows in a large corpus. On a recent word analogy task our model obtains 75{\%} accuracy, an improvement of 11{\%} over Mikolov et al. (2013). It also outperforms related word vector models on similarity tasks and named entity recognition.},
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
doi = {10.3115/v1/D14-1162},
file = {:Users/bigsea/Dropbox/Mendely/Pennington, Socher, Manning - 2014 - GloVe Global Vectors for Word Representation.pdf:pdf},
journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing},
mendeley-groups = {cQA},
pages = {1532--1543},
title = {{GloVe: Global Vectors for Word Representation}},
year = {2014}
}
@article{Qiu2015,
abstract = {Retrieving similar questions is very important in community-based question answering. A major challenge is the lexical gap in sentence match-ing. In this paper, we propose a convolutional neural tensor network architecture to encode the sentences in semantic space and model their in-teractions with a tensor layer. Our model inte-grates sentence modeling and semantic matching into a single model, which can not only capture the useful information with convolutional and pool-ing layers, but also learn the matching metrics be-tween the question and its answer. Besides, our model is a general architecture, with no need for the other knowledge such as lexical or syntac-tic analysis. The experimental results shows that our method outperforms the other methods on two matching tasks.},
author = {Qiu, Xipeng and Huang, Xuanjing},
file = {:Users/bigsea/Dropbox/Mendely/Qiu, Huang - 2015 - Convolutional Neural Tensor Network Architecture for Community-based Question Answering.pdf:pdf},
journal = {Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI)},
keywords = {Technical Papers — Natural Language Processing},
mendeley-groups = {cQA},
title = {{Convolutional Neural Tensor Network Architecture for Community-based Question Answering}},
year = {2015}
}
@article{Robertson1997,
abstract = {The relationship between the Robertson/Sparck Jones relevance weighting formula and the Croft/Harper version for no relevance information is discussed. A method of avoiding the negative weights sometimes implied by the Croft/Harper version is proposed, which turns out to involve a return to the original Sparck Jones inverse collection frequency weight. The paper then goes on to propose a new way of using small amounts of relevance information in the estimation of relevance weights. Some experiments using TREC data are reported. Copyright 1997 ACM.},
author = {Robertson, Stephen E. and Walker, Stephen},
doi = {10.1145/278459.258529},
file = {:Users/bigsea/Dropbox/Mendely/Robertson, Walker - 1997 - On relevance weights with little relevance information.pdf:pdf},
isbn = {0897918363},
issn = {01635840},
journal = {ACM SIGIR Forum},
mendeley-groups = {cQA},
number = {SI},
pages = {16--24},
title = {{On relevance weights with little relevance information}},
volume = {31},
year = {1997}
}
@article{Shen2015,
author = {Shen, Yikang and Rong, Wenge and Sun, Zhiwei and Ouyang, Yuanxin and Xiong, Zhang},
file = {:Users/bigsea/Dropbox/Mendely/Shen et al. - 2015 - Question Answer Matching for CQA System via Combining Lexical and Sequential Information.pdf:pdf},
journal = {Aaai},
keywords = {2010,Ai and the Web Track,al,bilotti et,cqa is proven success,easier to get an-,engine,for knowledge sharing since,furthermore,in natural language,it is easier for,their real information needs,to a web search,users to express,using cqa is also},
mendeley-groups = {cQA},
pages = {275--281},
title = {{Question / Answer Matching for CQA System via Combining Lexical and Sequential Information}},
year = {2015}
}
@article{Shtok2012,
abstract = {Community-based Question Answering sites, such as Yahoo! Answers or Baidu Zhidao, allow users to get answers to com- plex, detailed and personal questions from other users. How- ever, since answering a question depends on the ability and willingness of users to address the asker’s needs, a significant fraction of the questions remain unanswered. We measured that in Yahoo! Answers, this fraction represents 15{\%} of all incoming English questions. At the same time, we discov- ered that around 25{\%} of questions in certain categories are recurrent, at least at the question-title level, over a period of one year. We attempt to reduce the rate of unanswered questions in Yahoo! Answers by reusing the large repository of past re- solved questions, openly available on the site. More specifi- cally, we estimate the probability whether certain new ques- tions can be satisfactorily answered by a best answer from the past, using a statistical model specifically trained for this task. We leverage concepts and methods from query- performance prediction and natural language processing in order to extract a wide range of features for our model. The key challenge here is to achieve a level of quality similar to the one provided by the best human answerers. We evaluated our algorithm on offline data extracted from Yahoo! Answers, but more interestingly, also on online data by using three “live” answering robots that automatically provide past answers to new questions when a certain degree of confidence is reached. We report the success rate of these robots in three active Yahoo! Answers categories in terms of both accuracy, coverage and askers’ satisfaction. This work presents a first attempt, to the best of our knowledge, of automatic question answering to questions of social nature, by reusing past answers of high quality.},
author = {Shtok, Anna and Dror, Gideon and Maarek, Yoelle and Szpektor, Idan},
doi = {10.1145/2187836.2187939},
file = {:Users/bigsea/Dropbox/Mendely/Shtok et al. - 2012 - Learning from the past.pdf:pdf},
isbn = {9781450312295},
journal = {Proceedings of the 21st international conference on World Wide Web - WWW '12},
keywords = {automatic question answering,community-based question answering},
mendeley-groups = {cQA},
pages = {759},
title = {{Learning from the past}},
url = {http://dl.acm.org/citation.cfm?doid=2187836.2187939},
year = {2012}
}
@article{Surdeanu2008,
abstract = {This work describes an answer ranking engine for non-factoid questions built using a large online community-generated question-answer collection (Yahoo! Answers). We show how such collections may be used to effectively set up large supervised learning experiments. Furthermore we investigate a wide range of feature types, some exploiting NLP proces- sors, and demonstrate that using them in com- bination leads to considerable improvements in accuracy.},
author = {Surdeanu, Mihai and Ciaramita, Massimiliano and Zaragoza, Hugo},
file = {:Users/bigsea/Dropbox/Mendely/Surdeanu, Ciaramita, Zaragoza - 2008 - Learning to Rank Answers on Large Online QA Collections.pdf:pdf},
isbn = {9781932432046},
journal = {Proceedings of the ACL-08: HLT},
mendeley-groups = {cQA},
number = {June},
pages = {719--727},
title = {{Learning to Rank Answers on Large Online QA Collections}},
year = {2008}
}
@article{Surdeanu2011,
abstract = {This work investigates the use of linguistically motivated features to improve search, in par- ticular for ranking answers to non-factoid questions. We show that it is possible to exploit existing large collections of question–answer pairs (fromonline social Question Answering sites) to extract such features and train ranking models which combine them effectively.We investigate a wide range of feature types, some exploiting natural language processing such as coarse word sense disambiguation, named-entity identification, syntactic parsing, and semantic role label- ing. Our experiments demonstrate that linguistic features, in combination, yield considerable improvements in accuracy.Depending on the system settings we measure relative improvements of 14{\%} to 21{\%} in Mean Reciprocal Rank and Precision@1, providing one of themost compelling evidence to date that complex linguistic features such asword senses and semantic roles can have a significant impact on large-scale information retrieval tasks.},
author = {Surdeanu, Mihai and Ciaramita, Massimiliano and Zaragoza, Hugo},
doi = {10.1162/COLI{\_}a{\_}00051},
file = {:Users/bigsea/Dropbox/Mendely/Surdeanu, Ciaramita, Zaragoza - 2011 - Learning to Rank Answers to Non-Factoid Questions from Web Collections.pdf:pdf},
isbn = {9781932432046},
issn = {0891-2017},
journal = {Computational Linguistics},
mendeley-groups = {cQA},
number = {2},
pages = {351--383},
title = {{Learning to Rank Answers to Non-Factoid Questions from Web Collections}},
volume = {37},
year = {2011}
}
@article{Tan2015,
abstract = {In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework, the other is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. Experimental results on a public insurance-domain dataset demonstrate that the extended models substantially outperform two state-of-the-art non-DL baselines and a strong DL baseline.},
archivePrefix = {arXiv},
arxivId = {1511.04108},
author = {Tan, Ming and Xiang, Bing and Zhou, Bowen},
eprint = {1511.04108},
file = {:Users/bigsea/Dropbox/Mendely/Tan, Xiang, Zhou - 2015 - LSTM-based Deep Learning Models for non-factoid answer selection.pdf:pdf},
mendeley-groups = {cQA},
title = {{LSTM-based Deep Learning Models for non-factoid answer selection}},
year = {2015}
}
@article{Wang2010,
author = {Wang, B and Wang, Xiaolong and Sun, C and Liu, Bingquan and Sun, Lin},
file = {:Users/bigsea/Dropbox/Mendely/Wang et al. - 2010 - Modeling semantic relevance for question-answer pairs in web social communities.pdf:pdf},
journal = {Proceeding ACL '10 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
mendeley-groups = {cQA},
number = {July},
pages = {1230--1238},
title = {{Modeling semantic relevance for question-answer pairs in web social communities}},
url = {http://dl.acm.org/citation.cfm?id=1858806},
year = {2010}
}
@article{Wang2014,
author = {Wang, Quan and Liu, Jing and Wang, Bin and Guo, Li},
file = {:Users/bigsea/Dropbox/Mendely/Wang et al. - 2014 - A Regularized Competition Model for Question Difficulty Estimation in Community Question Answering Services.pdf:pdf},
journal = {Emnlp},
mendeley-groups = {cQA},
pages = {1115--1126},
title = {{A Regularized Competition Model for Question Difficulty Estimation in Community Question Answering Services}},
year = {2014}
}
@article{Zhou2016,
author = {Zhou, Guangyou and Zhou, Yin and He, Tingting and Wu, Wensheng},
doi = {10.1016/j.knosys.2015.11.002},
file = {:Users/bigsea/Dropbox/Mendely/Zhou et al. - 2016 - Learning Semantic Representations with Neural Networks for Community Question Answering Retrieval.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Community question answering,Question retrieval,Te,community question answering},
mendeley-groups = {cQA},
pages = {75--83},
publisher = {Elsevier B.V.},
title = {{Learning Semantic Representations with Neural Networks for Community Question Answering Retrieval}},
url = {http://dx.doi.org/10.1016/j.knosys.2015.11.002},
volume = {93},
year = {2016}
}
@article{Zhou,
abstract = {In this paper, the answer selection problem in community question answering (CQA) is regarded as an answer sequence label-ing task, and a novel approach is proposed based on the recurrent architecture for this problem. Our approach applies convo-lution neural networks (CNNs) to learn-ing the joint representation of question-answer pair firstly, and then uses the joint representation as input of the long short-term memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Exper-iments conducted on the SemEval 2015 CQA dataset shows the effectiveness of our approach.},
author = {Zhou, Xiaoqiang and Hu, Baotian and Chen, Qingcai and Tang, Buzhou and Wang, Xiaolong},
file = {:Users/bigsea/Dropbox/Mendely/Zhou et al. - Unknown - Answer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering.pdf:pdf},
mendeley-groups = {cQA},
title = {{Answer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering}}
}

@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza- tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar- ison with a large previous study that used grid search and manual search to configure neural net- works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con- figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent “High Throughput”methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that randomsearch is a natural base- line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {Bergstra, James and Bengio, Yoshua},
file = {:Users/bigsea/Dropbox/Mendely/Bergstra, Bengio - 2012 - Random Search for Hyper-Parameter Optimization.pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface},
mendeley-groups = {cQA},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}

